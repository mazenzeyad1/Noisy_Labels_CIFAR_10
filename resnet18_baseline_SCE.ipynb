{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV7Lc5jhIYqh"
      },
      "source": [
        "# impoort Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kBgMokBYIZro"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "%matplotlib inline\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.models import resnet34\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axjr8PCQIh-E",
        "outputId": "874fa5c9-54e8-49e8-9a35-ac0e31e30df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:06<00:00, 27801754.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Define label noise levels\n",
        "noise_levels = [0.1, 0.3, 0.5, 0.8, 0.9]\n",
        "\n",
        "# Define class names\n",
        "class_names = [\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "]\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementation of SCELoss and Label Noise Functions"
      ],
      "metadata": {
        "id": "gyqxhIHULoAv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6NF54SjsIlao"
      },
      "outputs": [],
      "source": [
        "# SCELoss class definition\n",
        "class SCELoss(torch.nn.Module):\n",
        "    def __init__(self, alpha, beta, num_classes=10):\n",
        "        super(SCELoss, self).__init__()\n",
        "        self.alpha = alpha  # Weight for the cross-entropy loss component\n",
        "        self.beta = beta  # Weight for the reverse cross-entropy loss component\n",
        "        self.num_classes = num_classes  # Number of classes in the dataset\n",
        "        self.cross_entropy = torch.nn.CrossEntropyLoss()  # Standard cross-entropy loss\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        ce = self.cross_entropy(pred, labels)  # Calculate the standard cross-entropy loss\n",
        "        pred = F.softmax(pred, dim=1)  # Apply softmax to predictions\n",
        "        pred = torch.clamp(pred, min=1e-7, max=1.0)  # Clamp values to avoid log(0)\n",
        "        label_one_hot = F.one_hot(labels, self.num_classes).float()  # Convert labels to one-hot encoding\n",
        "        label_one_hot = torch.clamp(label_one_hot, min=1e-4, max=1.0)  # Clamp values for stability\n",
        "        rce = (-1 * torch.sum(pred * torch.log(label_one_hot), dim=1))  # Calculate reverse cross-entropy\n",
        "        loss = self.alpha * ce + self.beta * rce.mean()  # Combine the two components of the loss\n",
        "        return loss\n",
        "\n",
        "    # Function to apply symmetric label noise\n",
        "def symmetric_label_noise(labels, epsilon):\n",
        "    noisy_labels = []\n",
        "    for label in labels:\n",
        "        if random.random() < epsilon:\n",
        "            # With probability epsilon, pick a random label different from the true label\n",
        "            noisy_label = random.choice([i for i in range(10) if i != label])\n",
        "            noisy_labels.append(noisy_label)\n",
        "        else:\n",
        "            noisy_labels.append(label)  # With remaining probability, keep the original label\n",
        "    return noisy_labels\n",
        "\n",
        "def asymmetric_label_noise( labels, epsilon):\n",
        "    noisy_labels = []\n",
        "    for label in labels:\n",
        "       # Apply label-specific noise based on the predefined noise pattern\n",
        "        if label == 9:  # Check if the label is 'bird'\n",
        "            if random.random() < epsilon:\n",
        "                noisy_label = 0  # Flip 'bird' to 'airplane'\n",
        "            else:\n",
        "                noisy_label = label\n",
        "        elif label == 2:  # Check if the label is 'deer'\n",
        "            if random.random() < epsilon:\n",
        "                noisy_label = 7  # Flip 'deer' to 'horse'\n",
        "            else:\n",
        "                noisy_label = label\n",
        "        elif label == 3:  # Check if the label is 'cat'\n",
        "            if random.random() < epsilon:\n",
        "                noisy_label = 5  # Flip 'cat' to 'dog'\n",
        "            else:\n",
        "                noisy_label = label\n",
        "        elif label == 5:  # Check if the label is 'dog'\n",
        "            if random.random() < epsilon:\n",
        "                noisy_label = 3  # Flip 'dog' to 'cat'\n",
        "            else:\n",
        "                noisy_label = label\n",
        "        elif label == 7:  # Check if the label is 'truck'\n",
        "            if random.random() < epsilon:\n",
        "                noisy_label = 1  # Flip 'truck' to 'automobile'\n",
        "            else:\n",
        "                noisy_label = label\n",
        "        else:\n",
        "            noisy_label = label # For other classes, keep the label as is\n",
        "        noisy_labels.append(noisy_label)\n",
        "\n",
        "    noisy_labels = torch.tensor(noisy_labels) # Convert list to tensor\n",
        "    return noisy_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\"Model Training and Testing Functions with Label Noise Handling"
      ],
      "metadata": {
        "id": "s4PvkUclLjZn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8FQjKSm0Ipp8"
      },
      "outputs": [],
      "source": [
        "def train_model(train_loader, model, criterion, optimizer, noise_fn, epsilon):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0  # Initialize the running loss\n",
        "    correct = 0  # Count of correctly predicted labels\n",
        "    total = 0  # Total number of labels\n",
        "\n",
        "    for data, labels in train_loader:  # Iterate over the training data\n",
        "        optimizer.zero_grad()  # Reset gradients to zero\n",
        "        data, labels = data.cuda(), labels.cuda()  # Move data and labels to GPU\n",
        "        noisy_labels = noise_fn(labels.tolist(), epsilon)  # Apply label noise\n",
        "\n",
        "        outputs = model(data)  # Forward pass: compute predicted outputs\n",
        "        loss = criterion(outputs, torch.tensor(noisy_labels).cuda())  # Calculate loss\n",
        "        loss.backward()  # Backward pass: compute gradient\n",
        "        optimizer.step()  # Perform a single optimization step\n",
        "\n",
        "        running_loss += loss.item()  # Update running loss\n",
        "        _, predicted = outputs.max(1)  # Get the predictions\n",
        "        total += labels.size(0)  # Update the total number of labels\n",
        "        correct += predicted.eq(torch.tensor(noisy_labels).cuda()).sum().item()  # Update correct predictions\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)  # Calculate average loss\n",
        "    train_accuracy = 100 * correct / total  # Calculate training accuracy\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "def test_model(test_loader, model):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0  # Count of correctly predicted labels\n",
        "    total = 0  # Total number of labels\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations\n",
        "        for data, labels in test_loader:  # Iterate over the test data\n",
        "            data, labels = data.cuda(), labels.cuda()  # Move data and labels to GPU\n",
        "            outputs = model(data)  # Forward pass: compute predicted outputs\n",
        "            _, predicted = outputs.max(1)  # Get the predictions\n",
        "            total += labels.size(0)  # Update the total number of labels\n",
        "            correct += predicted.eq(labels).sum().item()  # Update correct predictions\n",
        "\n",
        "    test_accuracy = 100 * correct / total  # Calculate test accuracy\n",
        "    return test_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and Testing Loop for Model with Symmetric and Asymmetric Label Noise\""
      ],
      "metadata": {
        "id": "9ZESRUp6PvCe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKd_EokEIsoY",
        "outputId": "ce1c66c9-797f-4f43-ee0e-382e095c85d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symmetric Noise, Epsilon=0.1: Average Train Accuracy: 77.57%, Test Accuracy: 78.55%, Training Time: 375.45s, Inference Time: 0.00332s\n",
            "Asymmetric Noise, Epsilon=0.1: Average Train Accuracy: 83.09%, Test Accuracy: 78.62%, Training Time: 381.90s, Inference Time: 0.00332s\n",
            "Symmetric Noise, Epsilon=0.3: Average Train Accuracy: 57.84%, Test Accuracy: 75.97%, Training Time: 392.12s, Inference Time: 0.00419s\n",
            "Asymmetric Noise, Epsilon=0.3: Average Train Accuracy: 74.42%, Test Accuracy: 78.20%, Training Time: 373.42s, Inference Time: 0.00419s\n",
            "Symmetric Noise, Epsilon=0.5: Average Train Accuracy: 39.08%, Test Accuracy: 72.45%, Training Time: 372.44s, Inference Time: 0.00343s\n",
            "Asymmetric Noise, Epsilon=0.5: Average Train Accuracy: 67.94%, Test Accuracy: 58.78%, Training Time: 372.60s, Inference Time: 0.00343s\n",
            "Symmetric Noise, Epsilon=0.8: Average Train Accuracy: 12.69%, Test Accuracy: 33.60%, Training Time: 373.02s, Inference Time: 0.00427s\n",
            "Asymmetric Noise, Epsilon=0.8: Average Train Accuracy: 78.88%, Test Accuracy: 45.53%, Training Time: 375.11s, Inference Time: 0.00427s\n",
            "Symmetric Noise, Epsilon=0.9: Average Train Accuracy: 9.97%, Test Accuracy: 9.24%, Training Time: 378.56s, Inference Time: 0.00428s\n",
            "Asymmetric Noise, Epsilon=0.9: Average Train Accuracy: 83.40%, Test Accuracy: 45.42%, Training Time: 381.41s, Inference Time: 0.00428s\n",
            "Symmetric Noise, Epsilon=0.1: Average Train Accuracy: 77.74%, Test Accuracy: 77.22%, Training Time: 370.97s, Inference Time: 0.00402s\n",
            "Asymmetric Noise, Epsilon=0.1: Average Train Accuracy: 83.04%, Test Accuracy: 79.08%, Training Time: 359.49s, Inference Time: 0.00402s\n",
            "Symmetric Noise, Epsilon=0.3: Average Train Accuracy: 57.78%, Test Accuracy: 76.47%, Training Time: 367.44s, Inference Time: 0.00359s\n",
            "Asymmetric Noise, Epsilon=0.3: Average Train Accuracy: 74.43%, Test Accuracy: 78.07%, Training Time: 362.98s, Inference Time: 0.00359s\n",
            "Symmetric Noise, Epsilon=0.5: Average Train Accuracy: 39.04%, Test Accuracy: 73.47%, Training Time: 366.03s, Inference Time: 0.00347s\n",
            "Asymmetric Noise, Epsilon=0.5: Average Train Accuracy: 68.01%, Test Accuracy: 70.39%, Training Time: 364.03s, Inference Time: 0.00347s\n",
            "Symmetric Noise, Epsilon=0.8: Average Train Accuracy: 12.46%, Test Accuracy: 33.85%, Training Time: 371.66s, Inference Time: 0.00364s\n",
            "Asymmetric Noise, Epsilon=0.8: Average Train Accuracy: 78.95%, Test Accuracy: 45.89%, Training Time: 361.24s, Inference Time: 0.00364s\n",
            "Symmetric Noise, Epsilon=0.9: Average Train Accuracy: 9.64%, Test Accuracy: 8.79%, Training Time: 358.14s, Inference Time: 0.00329s\n",
            "Asymmetric Noise, Epsilon=0.9: Average Train Accuracy: 83.31%, Test Accuracy: 46.55%, Training Time: 357.75s, Inference Time: 0.00329s\n",
            "Symmetric Noise, Epsilon=0.1: Average Train Accuracy: 77.46%, Test Accuracy: 78.84%, Training Time: 355.69s, Inference Time: 0.00331s\n",
            "Asymmetric Noise, Epsilon=0.1: Average Train Accuracy: 83.14%, Test Accuracy: 78.36%, Training Time: 355.67s, Inference Time: 0.00331s\n",
            "Symmetric Noise, Epsilon=0.3: Average Train Accuracy: 57.80%, Test Accuracy: 76.86%, Training Time: 371.46s, Inference Time: 0.00411s\n",
            "Asymmetric Noise, Epsilon=0.3: Average Train Accuracy: 74.40%, Test Accuracy: 77.84%, Training Time: 359.49s, Inference Time: 0.00411s\n",
            "Symmetric Noise, Epsilon=0.5: Average Train Accuracy: 39.38%, Test Accuracy: 73.58%, Training Time: 410.26s, Inference Time: 0.00373s\n",
            "Asymmetric Noise, Epsilon=0.5: Average Train Accuracy: 68.33%, Test Accuracy: 53.88%, Training Time: 405.27s, Inference Time: 0.00373s\n",
            "Symmetric Noise, Epsilon=0.8: Average Train Accuracy: 12.27%, Test Accuracy: 30.19%, Training Time: 379.31s, Inference Time: 0.00338s\n",
            "Asymmetric Noise, Epsilon=0.8: Average Train Accuracy: 78.78%, Test Accuracy: 44.82%, Training Time: 388.66s, Inference Time: 0.00338s\n",
            "Symmetric Noise, Epsilon=0.9: Average Train Accuracy: 9.81%, Test Accuracy: 9.75%, Training Time: 393.07s, Inference Time: 0.00356s\n",
            "Asymmetric Noise, Epsilon=0.9: Average Train Accuracy: 83.09%, Test Accuracy: 45.11%, Training Time: 372.58s, Inference Time: 0.00356s\n",
            "Symmetric Noise, Epsilon=0.1: Average Train Accuracy: 77.22%, Test Accuracy: 78.68%, Training Time: 359.71s, Inference Time: 0.00366s\n",
            "Asymmetric Noise, Epsilon=0.1: Average Train Accuracy: 83.05%, Test Accuracy: 79.06%, Training Time: 387.13s, Inference Time: 0.00366s\n",
            "Symmetric Noise, Epsilon=0.3: Average Train Accuracy: 57.84%, Test Accuracy: 76.17%, Training Time: 354.47s, Inference Time: 0.00343s\n",
            "Asymmetric Noise, Epsilon=0.3: Average Train Accuracy: 74.54%, Test Accuracy: 77.87%, Training Time: 365.29s, Inference Time: 0.00343s\n",
            "Symmetric Noise, Epsilon=0.5: Average Train Accuracy: 39.04%, Test Accuracy: 73.09%, Training Time: 359.41s, Inference Time: 0.00338s\n",
            "Asymmetric Noise, Epsilon=0.5: Average Train Accuracy: 67.84%, Test Accuracy: 63.65%, Training Time: 366.64s, Inference Time: 0.00338s\n",
            "Symmetric Noise, Epsilon=0.8: Average Train Accuracy: 12.29%, Test Accuracy: 31.01%, Training Time: 370.06s, Inference Time: 0.00362s\n",
            "Asymmetric Noise, Epsilon=0.8: Average Train Accuracy: 78.75%, Test Accuracy: 46.02%, Training Time: 367.72s, Inference Time: 0.00362s\n",
            "Symmetric Noise, Epsilon=0.9: Average Train Accuracy: 10.11%, Test Accuracy: 7.66%, Training Time: 362.13s, Inference Time: 0.00414s\n",
            "Asymmetric Noise, Epsilon=0.9: Average Train Accuracy: 83.44%, Test Accuracy: 45.79%, Training Time: 367.63s, Inference Time: 0.00414s\n",
            "Symmetric Noise, Epsilon=0.1: Average Train Accuracy: 77.63%, Test Accuracy: 78.20%, Training Time: 367.56s, Inference Time: 0.00407s\n",
            "Asymmetric Noise, Epsilon=0.1: Average Train Accuracy: 83.16%, Test Accuracy: 78.96%, Training Time: 362.13s, Inference Time: 0.00407s\n",
            "Symmetric Noise, Epsilon=0.3: Average Train Accuracy: 57.09%, Test Accuracy: 76.87%, Training Time: 361.34s, Inference Time: 0.00414s\n",
            "Asymmetric Noise, Epsilon=0.3: Average Train Accuracy: 74.41%, Test Accuracy: 77.73%, Training Time: 366.18s, Inference Time: 0.00414s\n",
            "Symmetric Noise, Epsilon=0.5: Average Train Accuracy: 39.78%, Test Accuracy: 72.98%, Training Time: 375.97s, Inference Time: 0.00357s\n",
            "Asymmetric Noise, Epsilon=0.5: Average Train Accuracy: 67.78%, Test Accuracy: 68.00%, Training Time: 370.83s, Inference Time: 0.00357s\n",
            "Symmetric Noise, Epsilon=0.8: Average Train Accuracy: 12.59%, Test Accuracy: 34.26%, Training Time: 380.41s, Inference Time: 0.00386s\n",
            "Asymmetric Noise, Epsilon=0.8: Average Train Accuracy: 78.45%, Test Accuracy: 45.90%, Training Time: 382.83s, Inference Time: 0.00386s\n",
            "Symmetric Noise, Epsilon=0.9: Average Train Accuracy: 9.97%, Test Accuracy: 7.75%, Training Time: 379.26s, Inference Time: 0.00338s\n",
            "Asymmetric Noise, Epsilon=0.9: Average Train Accuracy: 83.18%, Test Accuracy: 46.18%, Training Time: 375.76s, Inference Time: 0.00338s\n",
            "Symmetric Noise, Epsilon=0.1: Average Train Accuracy: 77.06%, Test Accuracy: 76.04%, Training Time: 376.58s, Inference Time: 0.00358s\n",
            "Asymmetric Noise, Epsilon=0.1: Average Train Accuracy: 83.36%, Test Accuracy: 79.22%, Training Time: 376.42s, Inference Time: 0.00358s\n",
            "Symmetric Noise, Epsilon=0.3: Average Train Accuracy: 57.78%, Test Accuracy: 77.27%, Training Time: 373.60s, Inference Time: 0.00333s\n",
            "Asymmetric Noise, Epsilon=0.3: Average Train Accuracy: 74.49%, Test Accuracy: 78.71%, Training Time: 372.95s, Inference Time: 0.00333s\n",
            "Symmetric Noise, Epsilon=0.5: Average Train Accuracy: 39.16%, Test Accuracy: 73.20%, Training Time: 370.18s, Inference Time: 0.00422s\n",
            "Asymmetric Noise, Epsilon=0.5: Average Train Accuracy: 67.86%, Test Accuracy: 63.42%, Training Time: 367.79s, Inference Time: 0.00422s\n",
            "Symmetric Noise, Epsilon=0.8: Average Train Accuracy: 12.43%, Test Accuracy: 37.70%, Training Time: 369.34s, Inference Time: 0.00337s\n",
            "Asymmetric Noise, Epsilon=0.8: Average Train Accuracy: 78.64%, Test Accuracy: 45.37%, Training Time: 383.07s, Inference Time: 0.00337s\n",
            "Symmetric Noise, Epsilon=0.9: Average Train Accuracy: 10.08%, Test Accuracy: 6.15%, Training Time: 372.82s, Inference Time: 0.00440s\n",
            "Asymmetric Noise, Epsilon=0.9: Average Train Accuracy: 83.33%, Test Accuracy: 44.91%, Training Time: 372.31s, Inference Time: 0.00440s\n",
            "Symmetric Noise, Epsilon=0.1: Average Train Accuracy: 77.39%, Test Accuracy: 79.13%, Training Time: 371.47s, Inference Time: 0.00341s\n",
            "Asymmetric Noise, Epsilon=0.1: Average Train Accuracy: 83.20%, Test Accuracy: 77.63%, Training Time: 368.61s, Inference Time: 0.00341s\n",
            "Symmetric Noise, Epsilon=0.3: Average Train Accuracy: 57.51%, Test Accuracy: 77.15%, Training Time: 370.68s, Inference Time: 0.00401s\n",
            "Asymmetric Noise, Epsilon=0.3: Average Train Accuracy: 74.32%, Test Accuracy: 77.16%, Training Time: 372.51s, Inference Time: 0.00401s\n",
            "Symmetric Noise, Epsilon=0.5: Average Train Accuracy: 39.16%, Test Accuracy: 72.07%, Training Time: 367.74s, Inference Time: 0.00431s\n",
            "Asymmetric Noise, Epsilon=0.5: Average Train Accuracy: 68.08%, Test Accuracy: 63.70%, Training Time: 367.88s, Inference Time: 0.00431s\n",
            "Symmetric Noise, Epsilon=0.8: Average Train Accuracy: 12.48%, Test Accuracy: 30.85%, Training Time: 367.60s, Inference Time: 0.00421s\n",
            "Asymmetric Noise, Epsilon=0.8: Average Train Accuracy: 78.79%, Test Accuracy: 45.84%, Training Time: 367.30s, Inference Time: 0.00421s\n",
            "Symmetric Noise, Epsilon=0.9: Average Train Accuracy: 10.10%, Test Accuracy: 11.02%, Training Time: 368.11s, Inference Time: 0.00334s\n",
            "Asymmetric Noise, Epsilon=0.9: Average Train Accuracy: 83.24%, Test Accuracy: 44.77%, Training Time: 369.11s, Inference Time: 0.00334s\n",
            "Symmetric Noise, Epsilon=0.1: Average Train Accuracy: 77.40%, Test Accuracy: 78.63%, Training Time: 369.53s, Inference Time: 0.00350s\n",
            "Asymmetric Noise, Epsilon=0.1: Average Train Accuracy: 82.92%, Test Accuracy: 78.30%, Training Time: 371.00s, Inference Time: 0.00350s\n",
            "Symmetric Noise, Epsilon=0.3: Average Train Accuracy: 57.11%, Test Accuracy: 76.66%, Training Time: 372.66s, Inference Time: 0.00338s\n",
            "Asymmetric Noise, Epsilon=0.3: Average Train Accuracy: 74.55%, Test Accuracy: 79.15%, Training Time: 370.38s, Inference Time: 0.00338s\n",
            "Symmetric Noise, Epsilon=0.5: Average Train Accuracy: 39.19%, Test Accuracy: 73.54%, Training Time: 370.12s, Inference Time: 0.00381s\n",
            "Asymmetric Noise, Epsilon=0.5: Average Train Accuracy: 67.99%, Test Accuracy: 58.66%, Training Time: 371.52s, Inference Time: 0.00381s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "for _ in range(10):\n",
        "    # Repeat the training process for 10 iterations.\n",
        "    for epsilon in noise_levels:\n",
        "        # Loop over different noise levels to train the model under varying conditions.\n",
        "\n",
        "        # Preparing data loaders for training and testing datasets.\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "        # Symmetric Noise Training\n",
        "        # Initialize the model with ResNet18 architecture and custom parameters.\n",
        "        model = resnet18(pretrained=False, num_classes=10).cuda()\n",
        "        # Use SCELoss as the criterion for training.\n",
        "        criterion = SCELoss(alpha=1, beta=1, num_classes=10)\n",
        "        # Set up the optimizer with Adam algorithm.\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        epochs = 15  # Define the number of training epochs.\n",
        "\n",
        "        # Begin timing the training process.\n",
        "        start_train_time = time.time()\n",
        "        total_train_accuracy_symmetric = 0\n",
        "        # Training loop for each epoch.\n",
        "        for epoch in range(epochs):\n",
        "            # Train the model and calculate train loss and accuracy.\n",
        "            train_loss, train_accuracy = train_model(train_loader, model, criterion, optimizer, symmetric_label_noise, epsilon)\n",
        "            total_train_accuracy_symmetric += train_accuracy\n",
        "        # Record end time of training.\n",
        "        end_train_time = time.time()\n",
        "        training_time_symmetric = end_train_time - start_train_time\n",
        "\n",
        "        # Calculate the average training accuracy across all epochs.\n",
        "        average_train_accuracy_symmetric = total_train_accuracy_symmetric / epochs\n",
        "\n",
        "        # Timing the testing process.\n",
        "        start_test_time = time.time()\n",
        "        # Test the model and calculate test accuracy.\n",
        "        test_accuracy_symmetric = test_model(test_loader, model)\n",
        "        end_test_time = time.time()\n",
        "        inference_time_symmetric = end_test_time - start_test_time\n",
        "\n",
        "        # Print results for symmetric noise training.\n",
        "        print(f\"Symmetric Noise, Epsilon={epsilon}: Average Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy_symmetric:.2f}%, Training Time: {training_time_symmetric:.2f}s, Inference Time: {(inference_time_symmetric/1000):.5f}s\")\n",
        "\n",
        "        # Asymmetric Noise Training\n",
        "        # Reinitialize the model for asymmetric noise training.\n",
        "        model = resnet18(pretrained=False, num_classes=10).cuda()\n",
        "        criterion = SCELoss(alpha=1, beta=1, num_classes=10)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        # Begin timing the training process for asymmetric noise.\n",
        "        start_train_time = time.time()\n",
        "        total_train_accuracy_asymmetric = 0\n",
        "        # Training loop for each epoch.\n",
        "        for epoch in range(epochs):\n",
        "            # Train the model with asymmetric label noise and calculate train loss and accuracy.\n",
        "            train_loss, train_accuracy = train_model(train_loader, model, criterion, optimizer, asymmetric_label_noise, epsilon)\n",
        "            total_train_accuracy_asymmetric += train_accuracy\n",
        "        # Record end time of training.\n",
        "        end_train_time = time.time()\n",
        "        training_time_asymmetric = end_train_time - start_train_time\n",
        "\n",
        "        # Calculate the average training accuracy across all epochs for asymmetric noise.\n",
        "        average_train_accuracy_asymmetric = total_train_accuracy_asymmetric / epochs\n",
        "\n",
        "        # Timing the testing process for asymmetric noise.\n",
        "        start_test_time = time.time()\n",
        "        # Test the model and calculate test accuracy for asymmetric noise.\n",
        "        test_accuracy_asymmetric = test_model(test_loader, model)\n",
        "        end_test_time = time.time()\n",
        "        inference_time_asymmetric = end_test_time - start_test_time\n",
        "\n",
        "        # Print results for asymmetric noise training.\n",
        "        print(f\"Asymmetric Noise, Epsilon={epsilon}: Average Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy_asymmetric:.2f}%, Training Time: {training_time_asymmetric:.2f}s, Inference Time: {(inference_time_symmetric/1000):.5f}s\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}